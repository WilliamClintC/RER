---
title: "Regression Analysis: Remittances and GDP"
format: 
  html:
    code-fold: false
    toc: true
  pdf:
    toc: true
jupyter: python3
---

# Regression Analysis: Value ~ Sending_Country_GDP + Receiving_Country_GDP

This document performs a comprehensive regression analysis examining the relationship between remittance values and GDP variables.

## Data Loading and Preparation

```{python}
import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from statsmodels.stats.diagnostic import het_breuschpagan
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Load the dataset
df = pd.read_csv(r'C:\Users\clint\Desktop\RER\Code\22.csv')

print("Dataset shape:", df.shape)
print("\nFirst few rows:")
df.head()
```

```{python}
# Data cleaning and preparation
print("Cleaning data...")
df['Value_cleaned'] = df['Value'].astype(str).str.replace(',', '').str.replace('"', '')
df['Value_cleaned'] = pd.to_numeric(df['Value_cleaned'], errors='coerce')

# Check for missing values
print("Missing values:")
print("Value_cleaned:", df['Value_cleaned'].isna().sum())
print("Sending_Country_GDP:", df['Sending_Country_GDP'].isna().sum())
print("Receiving_Country_GDP:", df['Receiving_Country_GDP'].isna().sum())

# Remove rows with missing values
regression_data = df.dropna(subset=['Value_cleaned', 'Sending_Country_GDP', 'Receiving_Country_GDP'])
print(f"\nDataset after removing missing values: {regression_data.shape[0]} rows")

# Summary statistics
regression_data[['Value_cleaned', 'Sending_Country_GDP', 'Receiving_Country_GDP']].describe()
```

## Regression Analysis

```{python}
# Prepare variables for regression analysis
y = regression_data['Value_cleaned']
X = regression_data[['Sending_Country_GDP', 'Receiving_Country_GDP']]
X = sm.add_constant(X)

# Fit the OLS regression model
model = sm.OLS(y, X).fit()

# Create R-style output formatting
def format_r_style_summary(model, y, X):
    """Format regression output to match R's summary() function exactly"""
    
    n = len(y)
    k = X.shape[1] - 1  # Number of predictors (excluding intercept)
    dof = n - X.shape[1]  # Degrees of freedom
    
    print("Call:")
    print(f"lm(formula = {y.name} ~ {' + '.join(X.columns[1:])}, data = regression_data)")
    
    print("\nResiduals:")
    residuals = model.resid
    res_quantiles = np.percentile(residuals, [0, 25, 50, 75, 100])
    print(f"{'Min':<8} {'1Q':<8} {'Median':<8} {'3Q':<8} {'Max':<8}")
    print(f"{res_quantiles[0]:<8.0f} {res_quantiles[1]:<8.0f} {res_quantiles[2]:<8.0f} {res_quantiles[3]:<8.0f} {res_quantiles[4]:<8.0f}")
    
    print("\nCoefficients:")
    print(f"{'':>25} {'Estimate':<12} {'Std. Error':<12} {'t value':<8} {'Pr(>|t|)':<12}")
    
    # Format coefficient names to match R
    coef_names = ['(Intercept)'] + [col for col in X.columns[1:]]
    
    for i, name in enumerate(coef_names):
        estimate = model.params[i]
        std_err = model.bse[i]
        t_val = model.tvalues[i]
        p_val = model.pvalues[i]
        
        # Format p-value significance stars like R
        if p_val < 0.001:
            sig = " ***"
        elif p_val < 0.01:
            sig = " ** "
        elif p_val < 0.05:
            sig = " *  "
        elif p_val < 0.1:
            sig = " .  "
        else:
            sig = "    "
        
        # Format coefficient name
        coef_display = name if len(name) <= 25 else name[:22] + "..."
        
        print(f"{coef_display:<25} {estimate:<12.3e} {std_err:<12.3e} {t_val:<8.3f} {p_val:<8.6f}{sig}")
    
    print("---")
    print("Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1")
    
    # Residual standard error and R-squared info
    rse = np.sqrt(model.mse_resid)
    r_squared = model.rsquared
    adj_r_squared = model.rsquared_adj
    f_stat = model.fvalue
    f_pval = model.f_pvalue
    
    print(f"\nResidual standard error: {rse:.0f} on {dof} degrees of freedom")
    print(f"Multiple R-squared:  {r_squared:.6f},\tAdjusted R-squared:  {adj_r_squared:.6f}")
    print(f"F-statistic: {f_stat:.3f} on {k} and {dof} DF,  p-value: {f_pval:.5g}")

# Display R-style summary
format_r_style_summary(model, y, X)
```

## Diagnostic Tests

```{python}
# Variance Inflation Factor (VIF) for multicollinearity
print("Variance Inflation Factors:")
vif_data = pd.DataFrame()
vif_data["Variable"] = X.columns[1:]  # Exclude constant
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(1, X.shape[1])]
print(vif_data)

if any(vif_data["VIF"] > 5):
    print("‚ö†Ô∏è  Warning: High multicollinearity detected (VIF > 5)")
else:
    print("‚úÖ No serious multicollinearity issues (all VIF < 5)")

# Breusch-Pagan test for heteroscedasticity
try:
    bp_test = het_breuschpagan(model.resid, model.model.exog)
    print(f"\nüîç Breusch-Pagan Test for Heteroscedasticity:")
    print(f"   LM statistic: {bp_test[0]:.4f}")
    print(f"   p-value: {bp_test[1]:.6f}")
    if bp_test[1] < 0.05:
        print("   Result: Heteroscedasticity detected (p < 0.05)")
    else:
        print("   Result: No heteroscedasticity detected (p >= 0.05)")
except:
    print("‚ö†Ô∏è  Could not perform heteroscedasticity test")

# Jarque-Bera test for normality of residuals
jb_test = stats.jarque_bera(model.resid)
print(f"\nüìä Jarque-Bera Test for Normality of Residuals:")
print(f"   JB statistic: {jb_test[0]:.4f}")
print(f"   p-value: {jb_test[1]:.6f}")
if jb_test[1] < 0.05:
    print("   Result: ‚ùå Residuals are NOT normally distributed (p < 0.05)")
    print("   ‚ö†Ô∏è  This suggests model assumptions may be violated")
else:
    print("   Result: ‚úÖ Residuals appear normally distributed (p >= 0.05)")

# Durbin-Watson test for autocorrelation
try:
    from statsmodels.stats.stattools import durbin_watson
    dw_stat = durbin_watson(model.resid)
except ImportError:
    # Manual calculation if import fails
    residuals = model.resid
    dw_stat = np.sum(np.diff(residuals)**2) / np.sum(residuals**2)

print(f"\nüîÑ Durbin-Watson Statistic: {dw_stat:.4f}")
if dw_stat < 1.5 or dw_stat > 2.5:
    print("   Result: ‚ö†Ô∏è  Potential autocorrelation in residuals")
else:
    print("   Result: ‚úÖ No strong evidence of autocorrelation")
```

## Diagnostic Plots

```{python}
#| fig-cap: "Regression Diagnostic Plots"
#| fig-width: 15
#| fig-height: 10

plt.style.use('default')
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Regression Diagnostic Plots', fontsize=16, fontweight='bold')

# 1. Actual vs Predicted values
axes[0,0].scatter(y, model.fittedvalues, alpha=0.6, color='steelblue')
axes[0,0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
axes[0,0].set_xlabel('Actual Values')
axes[0,0].set_ylabel('Predicted Values')
axes[0,0].set_title('Actual vs Predicted Values')
axes[0,0].grid(True, alpha=0.3)

# Add R¬≤ annotation
r_squared = model.rsquared
axes[0,0].text(0.05, 0.95, f'R¬≤ = {r_squared:.4f}', transform=axes[0,0].transAxes, 
               bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))

# 2. Residuals vs Fitted
axes[0,1].scatter(model.fittedvalues, model.resid, alpha=0.6, color='green')
axes[0,1].axhline(y=0, color='r', linestyle='--', lw=2)
axes[0,1].set_xlabel('Fitted Values')
axes[0,1].set_ylabel('Residuals')
axes[0,1].set_title('Residuals vs Fitted Values')
axes[0,1].grid(True, alpha=0.3)

# 3. Q-Q plot for residuals normality
stats.probplot(model.resid, dist="norm", plot=axes[0,2])
axes[0,2].set_title('Q-Q Plot of Residuals')
axes[0,2].grid(True, alpha=0.3)

# 4. Histogram of residuals
axes[1,0].hist(model.resid, bins=50, density=True, alpha=0.7, color='lightcoral')
axes[1,0].set_xlabel('Residuals')
axes[1,0].set_ylabel('Density')
axes[1,0].set_title('Distribution of Residuals')
axes[1,0].grid(True, alpha=0.3)

# 5. Value vs Sending Country GDP
axes[1,1].scatter(regression_data['Sending_Country_GDP'], y, alpha=0.6, color='purple')
axes[1,1].set_xlabel('Sending Country GDP')
axes[1,1].set_ylabel('Value')
axes[1,1].set_title('Value vs Sending Country GDP')
axes[1,1].grid(True, alpha=0.3)

# 6. Value vs Receiving Country GDP
axes[1,2].scatter(regression_data['Receiving_Country_GDP'], y, alpha=0.6, color='orange')
axes[1,2].set_xlabel('Receiving Country GDP')
axes[1,2].set_ylabel('Value')
axes[1,2].set_title('Value vs Receiving Country GDP')
axes[1,2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

## Correlation Analysis

```{python}
#| fig-cap: "Correlation Matrix Heatmap"
#| fig-width: 8
#| fig-height: 6

# Correlation matrix
corr_matrix = regression_data[['Value_cleaned', 'Sending_Country_GDP', 'Receiving_Country_GDP']].corr()
print("Correlation Matrix:")
print(corr_matrix.round(4))

# Create correlation heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, 
            square=True, fmt='.4f', cbar_kws={'label': 'Correlation Coefficient'})
plt.title('Correlation Matrix Heatmap', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()
```

## Summary and Interpretation

### Regression Equation
```{python}
coeffs = model.params
print(f"Value = {coeffs[0]:.6f} + {coeffs[1]:.6f} √ó Sending_Country_GDP + {coeffs[2]:.6f} √ó Receiving_Country_GDP")
```

### Key Findings

- **R-squared**: {python} f"{model.rsquared:.4f} ({model.rsquared*100:.2f}% of variance explained)"
- **F-statistic**: {python} f"{model.fvalue:.3f} (p = {model.f_pvalue:.6f})"
- **Sample size**: {python} f"{len(y):,} observations"

### Coefficient Interpretation

```{python}
print("Coefficient Interpretation:")
for i, var in enumerate(['Constant', 'Sending_Country_GDP', 'Receiving_Country_GDP']):
    p_val = model.pvalues[i]
    coef_val = coeffs[i]
    sig = "‚úÖ Significant" if p_val < 0.05 else "‚ùå Not significant"
    
    if var == 'Constant':
        print(f"‚Ä¢ {var}: {coef_val:.6f} (p = {p_val:.6f}) {sig}")
    elif var == 'Sending_Country_GDP':
        effect = coef_val * 1e9  # Effect of $1 billion increase
        print(f"‚Ä¢ {var}: {coef_val:.6f} (p = {p_val:.6f}) {sig}")
        print(f"  ‚Üí For every $1 billion ‚Üë in sending country GDP, remittances ‚Üë by ${effect:.2f} million")
    else:  # Receiving_Country_GDP
        effect = coef_val * 1e9  # Effect of $1 billion increase
        print(f"‚Ä¢ {var}: {coef_val:.6f} (p = {p_val:.6f}) {sig}")
        if coef_val < 0:
            print(f"  ‚Üí For every $1 billion ‚Üë in receiving country GDP, remittances ‚Üì by ${abs(effect):.2f} million")
        else:
            print(f"  ‚Üí For every $1 billion ‚Üë in receiving country GDP, remittances ‚Üë by ${effect:.2f} million")
```

### Conclusions

The analysis reveals that:

1. **Low explanatory power**: The model explains only {python} f"{model.rsquared*100:.2f}%" of the variance in remittance values
2. **Sending country GDP**: Has a significant positive effect on remittances
3. **Receiving country GDP**: Does not significantly affect remittances  
4. **Other factors**: Migration patterns, policies, and other variables likely more important predictors

The significant relationship with sending country GDP suggests that economic capacity of the origin country matters for remittance flows, but GDP alone is not a strong predictor of remittance patterns.